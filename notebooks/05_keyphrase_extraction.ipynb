{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 05 — Keyphrase Extraction\n\nKeyphrase extraction serves two roles in SocraticPath: populating the concept map shown to the user, and generating search terms for Wikipedia context retrieval. KeyBERT (Grootendorst, 2020) is used because it requires no task-specific training — it ranks candidate n-grams by cosine similarity to the document embedding produced by a pre-trained sentence transformer (`all-MiniLM-L6-v2`; Reimers & Gurevych, 2019). Maximal Marginal Relevance (MMR; Carbonell & Goldstein, 1998) is applied to balance relevance against diversity, preventing semantically redundant keyphrases from dominating the extracted set."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "print(\"KeyBERT model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Climate change is one of the most pressing issues of our time. The scientific consensus \n",
    "is clear: human activities, particularly the burning of fossil fuels, are causing global \n",
    "temperatures to rise. This leads to more extreme weather events, rising sea levels, and \n",
    "threats to biodiversity. We need immediate action on renewable energy and carbon reduction.\n",
    "\"\"\"\n",
    "\n",
    "keywords = kw_model.extract_keywords(\n",
    "    sample_text,\n",
    "    keyphrase_ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "print(\"Extracted Keyphrases:\")\n",
    "for kw, score in keywords:\n",
    "    print(f\"  {kw}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximal Marginal Relevance (Carbonell & Goldstein, 1998) selects keyphrases that are relevant to the document while being dissimilar to one another. The `diversity` parameter (0 = maximum relevance, 1 = maximum diversity) is set to 0.5 for concept map extraction and 0.7 for retrieval queries, where broader coverage is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_diverse = kw_model.extract_keywords(\n",
    "    sample_text,\n",
    "    keyphrase_ngram_range=(1, 3),\n",
    "    stop_words='english',\n",
    "    top_n=10,\n",
    "    use_mmr=True,\n",
    "    diversity=0.7\n",
    ")\n",
    "\n",
    "print(\"Diverse Keyphrases (MMR):\")\n",
    "for kw, score in keywords_diverse:\n",
    "    print(f\"  {kw}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyphrases(\n",
    "    text,\n",
    "    model=None,\n",
    "    top_n=5,\n",
    "    ngram_range=(1, 2),\n",
    "    diversity=0.5,\n",
    "    use_mmr=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract keyphrases from text using KeyBERT.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text\n",
    "        model: KeyBERT model instance\n",
    "        top_n: Number of keyphrases to extract\n",
    "        ngram_range: Tuple of (min, max) n-gram sizes\n",
    "        diversity: MMR diversity parameter (0=max relevance, 1=max diversity)\n",
    "        use_mmr: Whether to use MMR for diversification\n",
    "    \n",
    "    Returns:\n",
    "        List of (keyphrase, score) tuples\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = kw_model\n",
    "    \n",
    "    if not text or len(text.strip()) < 10:\n",
    "        return []\n",
    "    \n",
    "    keywords = model.extract_keywords(\n",
    "        text,\n",
    "        keyphrase_ngram_range=ngram_range,\n",
    "        stop_words='english',\n",
    "        top_n=top_n,\n",
    "        use_mmr=use_mmr,\n",
    "        diversity=diversity\n",
    "    )\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_contexts = [\n",
    "    \"I believe that artificial intelligence will eventually replace most human jobs. The advances in machine learning and automation are accelerating, and companies are already using AI for tasks that humans used to do.\",\n",
    "    \n",
    "    \"Social media is destroying democracy. The spread of misinformation and the creation of echo chambers is making it impossible for people to agree on basic facts or have productive political discussions.\",\n",
    "    \n",
    "    \"I think everyone should be required to learn a programming language in school. Technology is everywhere now, and understanding code is as important as reading and writing.\"\n",
    "]\n",
    "\n",
    "print(\"Keyphrase Extraction Examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, context in enumerate(test_contexts, 1):\n",
    "    keyphrases = extract_keyphrases(context, top_n=5)\n",
    "    \n",
    "    print(f\"\\nContext {i}: {context[:80]}...\")\n",
    "    print(\"Keyphrases:\")\n",
    "    for kw, score in keyphrases:\n",
    "        print(f\"  - {kw} ({score:.3f})\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the concept map, keyphrases are extracted from the user input and the generated Socratic question. Results from each source are deduplicated and ranked by the maximum score across sources, giving priority to concepts that appear in multiple parts of the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_keyphrases(user_input, generated_question, retrieved_context=None, top_n=5):\n",
    "    \"\"\"\n",
    "    Extract keyphrases from all sources and combine them.\n",
    "    \n",
    "    Returns:\n",
    "        dict with keyphrases categorized by source\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'user_input': extract_keyphrases(user_input, top_n=top_n),\n",
    "        'generated_question': extract_keyphrases(generated_question, top_n=3),\n",
    "        'combined': []\n",
    "    }\n",
    "    \n",
    "    if retrieved_context:\n",
    "        results['retrieved_context'] = extract_keyphrases(retrieved_context, top_n=top_n)\n",
    "    \n",
    "    all_keyphrases = {}\n",
    "    for source, kws in results.items():\n",
    "        if source == 'combined':\n",
    "            continue\n",
    "        for kw, score in kws:\n",
    "            kw_lower = kw.lower()\n",
    "            if kw_lower not in all_keyphrases:\n",
    "                all_keyphrases[kw_lower] = {'phrase': kw, 'score': score, 'sources': []}\n",
    "            all_keyphrases[kw_lower]['sources'].append(source)\n",
    "            all_keyphrases[kw_lower]['score'] = max(all_keyphrases[kw_lower]['score'], score)\n",
    "    \n",
    "    sorted_kws = sorted(all_keyphrases.values(), key=lambda x: x['score'], reverse=True)\n",
    "    results['combined'] = sorted_kws[:top_n * 2]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = \"Climate change is not as serious as scientists claim because the weather has always changed throughout history.\"\n",
    "example_question = \"What specific evidence distinguishes current climate patterns from historical natural variations?\"\n",
    "example_context = \"The current rate of warming is unprecedented in the geological record. Ice core data shows CO2 levels are higher than any point in the last 800,000 years.\"\n",
    "\n",
    "all_kws = extract_all_keyphrases(\n",
    "    example_input,\n",
    "    example_question,\n",
    "    example_context\n",
    ")\n",
    "\n",
    "print(\"Multi-Source Keyphrase Extraction:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nFrom User Input:\")\n",
    "for kw, score in all_kws['user_input']:\n",
    "    print(f\"  - {kw} ({score:.3f})\")\n",
    "\n",
    "print(\"\\nFrom Generated Question:\")\n",
    "for kw, score in all_kws['generated_question']:\n",
    "    print(f\"  - {kw} ({score:.3f})\")\n",
    "\n",
    "print(\"\\nFrom Retrieved Context:\")\n",
    "for kw, score in all_kws['retrieved_context']:\n",
    "    print(f\"  - {kw} ({score:.3f})\")\n",
    "\n",
    "print(\"\\nCombined (Unique, Ranked):\")\n",
    "for item in all_kws['combined']:\n",
    "    sources = ', '.join(item['sources'])\n",
    "    print(f\"  - {item['phrase']} ({item['score']:.3f}) - from: {sources}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_concept_nodes(keyphrases_result, central_topic=None):\n",
    "    \"\"\"\n",
    "    Generate concept map nodes from keyphrases.\n",
    "    \n",
    "    Returns:\n",
    "        list of node dictionaries for React Flow\n",
    "    \"\"\"\n",
    "    nodes = []\n",
    "    \n",
    "    if central_topic:\n",
    "        nodes.append({\n",
    "            'id': 'central',\n",
    "            'type': 'topic',\n",
    "            'label': central_topic,\n",
    "            'position': {'x': 0, 'y': 0},\n",
    "            'data': {'score': 1.0, 'source': 'user'}\n",
    "        })\n",
    "    \n",
    "    for i, item in enumerate(keyphrases_result.get('combined', [])):\n",
    "        node_type = 'concept'\n",
    "        if 'generated_question' in item.get('sources', []):\n",
    "            node_type = 'question'\n",
    "        \n",
    "        nodes.append({\n",
    "            'id': f'concept_{i}',\n",
    "            'type': node_type,\n",
    "            'label': item['phrase'],\n",
    "            'position': {'x': 0, 'y': 0},\n",
    "            'data': {\n",
    "                'score': item['score'],\n",
    "                'sources': item['sources']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = generate_concept_nodes(all_kws, central_topic=\"Climate Change\")\n",
    "\n",
    "print(\"Generated Concept Nodes:\")\n",
    "for node in nodes:\n",
    "    print(f\"  [{node['type']}] {node['label']} (score: {node['data']['score']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../datasets/processed\")\n",
    "\n",
    "if (DATA_PATH / \"test_formatted.parquet\").exists():\n",
    "    test_df = pd.read_parquet(DATA_PATH / \"test_formatted.parquet\")\n",
    "    sample_df = test_df.head(100)\n",
    "    \n",
    "    print(\"Processing keyphrases for sample data...\")\n",
    "    \n",
    "    all_keyphrases = []\n",
    "    for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "        kws = extract_keyphrases(row['original_input'], top_n=5)\n",
    "        all_keyphrases.extend([kw for kw, _ in kws])\n",
    "    \n",
    "    keyphrase_counts = Counter(all_keyphrases)\n",
    "    top_keyphrases = keyphrase_counts.most_common(20)\n",
    "    \n",
    "    print(\"\\nMost Common Keyphrases in Dataset:\")\n",
    "    for kw, count in top_keyphrases:\n",
    "        print(f\"  {kw}: {count}\")\n",
    "else:\n",
    "    print(\"Test data not found. Run preprocessing notebook first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyphraseExtractor:\n",
    "    \"\"\"\n",
    "    Production-ready keyphrase extractor for SocraticPath.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = KeyBERT(model=model_name)\n",
    "    \n",
    "    def extract(\n",
    "        self,\n",
    "        text,\n",
    "        top_n=5,\n",
    "        ngram_range=(1, 2),\n",
    "        diversity=0.5\n",
    "    ):\n",
    "        \"\"\"Extract keyphrases from a single text.\"\"\"\n",
    "        if not text or len(text.strip()) < 10:\n",
    "            return []\n",
    "        \n",
    "        keywords = self.model.extract_keywords(\n",
    "            text,\n",
    "            keyphrase_ngram_range=ngram_range,\n",
    "            stop_words='english',\n",
    "            top_n=top_n,\n",
    "            use_mmr=True,\n",
    "            diversity=diversity\n",
    "        )\n",
    "        \n",
    "        return [{'phrase': kw, 'score': float(score)} for kw, score in keywords]\n",
    "    \n",
    "    def extract_for_retrieval(self, text, top_n=3):\n",
    "        \"\"\"Extract keyphrases optimized for API retrieval queries.\"\"\"\n",
    "        kws = self.extract(text, top_n=top_n, ngram_range=(1, 3), diversity=0.7)\n",
    "        return [kw['phrase'] for kw in kws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = KeyphraseExtractor()\n",
    "\n",
    "test_text = \"The government should invest more in renewable energy sources like solar and wind power to combat climate change.\"\n",
    "\n",
    "print(\"Standard Extraction:\")\n",
    "for kw in extractor.extract(test_text):\n",
    "    print(f\"  - {kw['phrase']} ({kw['score']:.3f})\")\n",
    "\n",
    "print(\"\\nFor Retrieval Queries:\")\n",
    "print(f\"  {extractor.extract_for_retrieval(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "OUTPUT_PATH = Path(\"../models/keybert_config\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"model_name\": \"all-MiniLM-L6-v2\",\n",
    "    \"default_top_n\": 5,\n",
    "    \"default_ngram_range\": [1, 2],\n",
    "    \"default_diversity\": 0.5,\n",
    "    \"retrieval_top_n\": 3,\n",
    "    \"retrieval_ngram_range\": [1, 3],\n",
    "    \"retrieval_diversity\": 0.7,\n",
    "    \"stop_words\": \"english\"\n",
    "}\n",
    "\n",
    "with open(OUTPUT_PATH / \"config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Configuration saved to {OUTPUT_PATH / 'config.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `KeyphraseExtractor` class is the interface used by the inference pipeline in notebook 06. The two extraction modes — `extract()` for concept maps (top_n=5, ngram_range=(1,2)) and `extract_for_retrieval()` for Wikipedia queries (top_n=3, ngram_range=(1,3)) — reflect different coverage requirements. Configuration is persisted to `models/keybert_config/config.json` for reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
