{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Context Retrieval with Google Gemini API\n",
    "\n",
    "This notebook sets up real-time context retrieval using Google's Gemini API. We will:\n",
    "\n",
    "1. Configure the Gemini API client\n",
    "2. Build retrieval functions for keyphrases\n",
    "3. Implement Wikipedia fallback\n",
    "4. Create a production-ready retrieval service\n",
    "\n",
    "---\n",
    "\n",
    "## API Setup\n",
    "\n",
    "Get your free API key from [Google AI Studio](https://aistudio.google.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import google.generativeai as genai\n",
    "import wikipediaapi\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Create a `.env` file in your project root with:\n",
    "```\n",
    "GEMINI_API_KEY=your_api_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    print(\"Warning: GEMINI_API_KEY not found in environment.\")\n",
    "    print(\"Set it using: os.environ['GEMINI_API_KEY'] = 'your_key'\")\n",
    "    GEMINI_API_KEY = input(\"Enter your Gemini API key: \")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "print(\"Gemini API configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "generation_config = genai.GenerationConfig(\n",
    "    temperature=0.3,\n",
    "    max_output_tokens=500,\n",
    "    top_p=0.8,\n",
    "    top_k=40\n",
    ")\n",
    "\n",
    "print(\"Gemini 1.5 Flash model initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Context Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context_gemini(keyphrases, max_retries=3):\n",
    "    \"\"\"\n",
    "    Retrieve educational context for keyphrases using Gemini API.\n",
    "    \n",
    "    Args:\n",
    "        keyphrases: List of keyphrase strings\n",
    "        max_retries: Number of retry attempts on failure\n",
    "    \n",
    "    Returns:\n",
    "        dict with context for each keyphrase\n",
    "    \"\"\"\n",
    "    if not keyphrases:\n",
    "        return {}\n",
    "    \n",
    "    prompt = f\"\"\"Provide brief, factual educational context for each of these topics. \n",
    "For each topic, give 2-3 sentences of objective information that would help someone \n",
    "understand and think critically about the topic.\n",
    "\n",
    "Topics: {', '.join(keyphrases)}\n",
    "\n",
    "Format your response as:\n",
    "TOPIC: [topic name]\n",
    "CONTEXT: [2-3 sentence explanation]\n",
    "\n",
    "Do not include opinions. Focus on established facts and key considerations.\"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "                prompt,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "            return parse_context_response(response.text, keyphrases)\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "                continue\n",
    "            print(f\"Gemini API error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_context_response(response_text, keyphrases):\n",
    "    \"\"\"Parse the structured response from Gemini.\"\"\"\n",
    "    result = {}\n",
    "    current_topic = None\n",
    "    current_context = []\n",
    "    \n",
    "    for line in response_text.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line.startswith('TOPIC:'):\n",
    "            if current_topic and current_context:\n",
    "                result[current_topic] = ' '.join(current_context)\n",
    "            current_topic = line.replace('TOPIC:', '').strip()\n",
    "            current_context = []\n",
    "        elif line.startswith('CONTEXT:'):\n",
    "            current_context.append(line.replace('CONTEXT:', '').strip())\n",
    "        elif current_topic and line:\n",
    "            current_context.append(line)\n",
    "    \n",
    "    if current_topic and current_context:\n",
    "        result[current_topic] = ' '.join(current_context)\n",
    "    \n",
    "    if not result:\n",
    "        for kp in keyphrases:\n",
    "            if kp.lower() in response_text.lower():\n",
    "                result[kp] = response_text[:500]\n",
    "                break\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_keyphrases = [\"climate change\", \"renewable energy\", \"carbon emissions\"]\n",
    "\n",
    "print(\"Testing Gemini Context Retrieval...\")\n",
    "context = retrieve_context_gemini(test_keyphrases)\n",
    "\n",
    "print(\"\\nRetrieved Context:\")\n",
    "for topic, ctx in context.items():\n",
    "    print(f\"\\n{topic}:\")\n",
    "    print(f\"  {ctx[:200]}...\" if len(ctx) > 200 else f\"  {ctx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = wikipediaapi.Wikipedia(\n",
    "    user_agent='SocraticPath/1.0 (https://github.com/socraticpath)',\n",
    "    language='en'\n",
    ")\n",
    "\n",
    "def retrieve_context_wikipedia(keyphrase, max_chars=500):\n",
    "    \"\"\"\n",
    "    Retrieve context from Wikipedia for a single keyphrase.\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'summary' and 'url' or None if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        page = wiki.page(keyphrase)\n",
    "        if page.exists():\n",
    "            summary = page.summary[:max_chars]\n",
    "            if len(page.summary) > max_chars:\n",
    "                last_period = summary.rfind('.')\n",
    "                if last_period > max_chars // 2:\n",
    "                    summary = summary[:last_period + 1]\n",
    "            \n",
    "            return {\n",
    "                'summary': summary,\n",
    "                'url': page.fullurl,\n",
    "                'title': page.title\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Wikipedia error for '{keyphrase}': {e}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Wikipedia Fallback...\")\n",
    "\n",
    "wiki_result = retrieve_context_wikipedia(\"machine learning\")\n",
    "if wiki_result:\n",
    "    print(f\"\\nTitle: {wiki_result['title']}\")\n",
    "    print(f\"URL: {wiki_result['url']}\")\n",
    "    print(f\"Summary: {wiki_result['summary'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Retrieval Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalResult(BaseModel):\n",
    "    keyphrase: str\n",
    "    context: str\n",
    "    source: str\n",
    "    url: Optional[str] = None\n",
    "\n",
    "\n",
    "class ContextRetriever:\n",
    "    \"\"\"\n",
    "    Production-ready context retrieval service.\n",
    "    Uses Gemini API with Wikipedia fallback.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=None):\n",
    "        if api_key:\n",
    "            genai.configure(api_key=api_key)\n",
    "        \n",
    "        self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        self.wiki = wikipediaapi.Wikipedia(\n",
    "            user_agent='SocraticPath/1.0',\n",
    "            language='en'\n",
    "        )\n",
    "        self.generation_config = genai.GenerationConfig(\n",
    "            temperature=0.3,\n",
    "            max_output_tokens=500\n",
    "        )\n",
    "    \n",
    "    def retrieve(self, keyphrases, use_fallback=True):\n",
    "        \"\"\"\n",
    "        Retrieve context for a list of keyphrases.\n",
    "        \n",
    "        Args:\n",
    "            keyphrases: List of keyphrase strings\n",
    "            use_fallback: Whether to use Wikipedia if Gemini fails\n",
    "        \n",
    "        Returns:\n",
    "            List of RetrievalResult objects\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        gemini_context = self._retrieve_gemini(keyphrases)\n",
    "        \n",
    "        for kp in keyphrases:\n",
    "            matched_key = None\n",
    "            for key in gemini_context:\n",
    "                if kp.lower() in key.lower() or key.lower() in kp.lower():\n",
    "                    matched_key = key\n",
    "                    break\n",
    "            \n",
    "            if matched_key and gemini_context.get(matched_key):\n",
    "                results.append(RetrievalResult(\n",
    "                    keyphrase=kp,\n",
    "                    context=gemini_context[matched_key],\n",
    "                    source='gemini'\n",
    "                ))\n",
    "            elif use_fallback:\n",
    "                wiki_result = self._retrieve_wikipedia(kp)\n",
    "                if wiki_result:\n",
    "                    results.append(RetrievalResult(\n",
    "                        keyphrase=kp,\n",
    "                        context=wiki_result['summary'],\n",
    "                        source='wikipedia',\n",
    "                        url=wiki_result['url']\n",
    "                    ))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _retrieve_gemini(self, keyphrases):\n",
    "        \"\"\"Internal Gemini retrieval.\"\"\"\n",
    "        prompt = f\"\"\"Provide brief, factual educational context for these topics.\n",
    "For each, give 2-3 objective sentences.\n",
    "\n",
    "Topics: {', '.join(keyphrases)}\n",
    "\n",
    "Format:\n",
    "TOPIC: [name]\n",
    "CONTEXT: [explanation]\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(\n",
    "                prompt,\n",
    "                generation_config=self.generation_config\n",
    "            )\n",
    "            return parse_context_response(response.text, keyphrases)\n",
    "        except Exception as e:\n",
    "            print(f\"Gemini retrieval error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def _retrieve_wikipedia(self, keyphrase):\n",
    "        \"\"\"Internal Wikipedia retrieval.\"\"\"\n",
    "        try:\n",
    "            page = self.wiki.page(keyphrase)\n",
    "            if page.exists():\n",
    "                summary = page.summary[:500]\n",
    "                last_period = summary.rfind('.')\n",
    "                if last_period > 250:\n",
    "                    summary = summary[:last_period + 1]\n",
    "                return {\n",
    "                    'summary': summary,\n",
    "                    'url': page.fullurl\n",
    "                }\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    def retrieve_single(self, keyphrase):\n",
    "        \"\"\"Convenience method for single keyphrase retrieval.\"\"\"\n",
    "        results = self.retrieve([keyphrase])\n",
    "        return results[0] if results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ContextRetriever()\n",
    "\n",
    "test_phrases = [\"artificial intelligence\", \"neural networks\", \"deep learning\"]\n",
    "\n",
    "print(\"Testing Combined Retriever...\")\n",
    "results = retriever.retrieve(test_phrases)\n",
    "\n",
    "print(\"\\nRetrieval Results:\")\n",
    "for r in results:\n",
    "    print(f\"\\n[{r.source.upper()}] {r.keyphrase}\")\n",
    "    print(f\"  {r.context[:150]}...\")\n",
    "    if r.url:\n",
    "        print(f\"  Source: {r.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Context for Socratic Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_socratic_context(user_input, keyphrases, retriever):\n",
    "    \"\"\"\n",
    "    Retrieve and format context specifically for Socratic question enhancement.\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'combined_context' and 'sources'\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(keyphrases)\n",
    "    \n",
    "    context_parts = []\n",
    "    sources = []\n",
    "    \n",
    "    for r in results:\n",
    "        context_parts.append(f\"{r.keyphrase}: {r.context}\")\n",
    "        sources.append({\n",
    "            'keyphrase': r.keyphrase,\n",
    "            'source': r.source,\n",
    "            'url': r.url\n",
    "        })\n",
    "    \n",
    "    combined = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    return {\n",
    "        'user_input': user_input,\n",
    "        'keyphrases': keyphrases,\n",
    "        'combined_context': combined,\n",
    "        'sources': sources,\n",
    "        'retrieval_results': results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I think vaccines are dangerous and the government is hiding the truth about their side effects.\"\n",
    "keyphrases = [\"vaccines\", \"vaccine safety\", \"clinical trials\"]\n",
    "\n",
    "enhanced = enhance_socratic_context(user_input, keyphrases, retriever)\n",
    "\n",
    "print(\"Enhanced Context for Socratic Question Generation:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nUser Input: {enhanced['user_input']}\")\n",
    "print(f\"\\nKeyphrases: {enhanced['keyphrases']}\")\n",
    "print(f\"\\nCombined Context ({len(enhanced['combined_context'])} chars):\")\n",
    "print(enhanced['combined_context'][:500])\n",
    "print(f\"\\nSources: {len(enhanced['sources'])} items\")\n",
    "for s in enhanced['sources']:\n",
    "    print(f\"  - {s['keyphrase']} ({s['source']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate Limiting and Caching Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import hashlib\n",
    "\n",
    "class CachedContextRetriever(ContextRetriever):\n",
    "    \"\"\"Context retriever with simple in-memory caching.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=None, cache_size=100):\n",
    "        super().__init__(api_key)\n",
    "        self._cache = {}\n",
    "        self._cache_size = cache_size\n",
    "        self._last_request_time = 0\n",
    "        self._min_request_interval = 0.5\n",
    "    \n",
    "    def _get_cache_key(self, keyphrases):\n",
    "        \"\"\"Generate cache key from keyphrases.\"\"\"\n",
    "        sorted_kps = tuple(sorted([kp.lower() for kp in keyphrases]))\n",
    "        return hashlib.md5(str(sorted_kps).encode()).hexdigest()\n",
    "    \n",
    "    def retrieve(self, keyphrases, use_fallback=True):\n",
    "        \"\"\"Retrieve with caching and rate limiting.\"\"\"\n",
    "        cache_key = self._get_cache_key(keyphrases)\n",
    "        \n",
    "        if cache_key in self._cache:\n",
    "            return self._cache[cache_key]\n",
    "        \n",
    "        elapsed = time.time() - self._last_request_time\n",
    "        if elapsed < self._min_request_interval:\n",
    "            time.sleep(self._min_request_interval - elapsed)\n",
    "        \n",
    "        results = super().retrieve(keyphrases, use_fallback)\n",
    "        \n",
    "        self._last_request_time = time.time()\n",
    "        \n",
    "        if len(self._cache) >= self._cache_size:\n",
    "            oldest_key = next(iter(self._cache))\n",
    "            del self._cache[oldest_key]\n",
    "        \n",
    "        self._cache[cache_key] = results\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_retriever = CachedContextRetriever()\n",
    "\n",
    "print(\"First request (not cached):\")\n",
    "start = time.time()\n",
    "results1 = cached_retriever.retrieve([\"quantum computing\"])\n",
    "print(f\"  Time: {time.time() - start:.2f}s\")\n",
    "\n",
    "print(\"\\nSecond request (cached):\")\n",
    "start = time.time()\n",
    "results2 = cached_retriever.retrieve([\"quantum computing\"])\n",
    "print(f\"  Time: {time.time() - start:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(\"../models/retrieval_config\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"gemini_model\": \"gemini-1.5-flash\",\n",
    "    \"generation_config\": {\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_output_tokens\": 500,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 40\n",
    "    },\n",
    "    \"wikipedia_config\": {\n",
    "        \"language\": \"en\",\n",
    "        \"max_summary_chars\": 500\n",
    "    },\n",
    "    \"cache_config\": {\n",
    "        \"enabled\": True,\n",
    "        \"max_size\": 100,\n",
    "        \"min_request_interval_seconds\": 0.5\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUTPUT_PATH / \"config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Configuration saved to {OUTPUT_PATH / 'config.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Retrieval Architecture:**\n",
    "\n",
    "1. **Primary**: Gemini 1.5 Flash (fast, cost-effective)\n",
    "2. **Fallback**: Wikipedia API (reliable, free, includes source URLs)\n",
    "\n",
    "**Key Classes:**\n",
    "- `ContextRetriever`: Basic retrieval with fallback\n",
    "- `CachedContextRetriever`: With in-memory caching and rate limiting\n",
    "\n",
    "**API Usage:**\n",
    "```python\n",
    "retriever = CachedContextRetriever()\n",
    "results = retriever.retrieve(['topic1', 'topic2'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Next Step**: Proceed to `07_inference_pipeline.ipynb` to build the complete inference pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
